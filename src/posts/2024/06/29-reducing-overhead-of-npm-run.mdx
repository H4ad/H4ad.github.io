---
title: Reducing overhead of npm run
date: 2024-06-29
dateModified: 2024-06-29
author: Vinícius Lourenço
tags: ['Node.js', 'Npm', 'Performance']
featuredImage: 29-reducing-overhead-of-npm-run.jpg
---

<small>
  Photo by{' '}
  <a href="https://unsplash.com/@marchingnapkin?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">
    Todd Morris
  </a>{' '}
  on{' '}
  <a href="https://unsplash.com/pt-br/fotografias/um-semaforo-com-um-painel-solar-em-cima-dele-hTbEKOfXixA?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">
    Unsplash
  </a>
</small>

## [Introduction](#introduction)

This year we've had a lot of discussions about overhead of `npm run` and alternatives like [bun run](https://bun.sh/docs/cli/run)
and recently released [node --run](https://nodejs.org/en/learn/command-line/run-nodejs-scripts-from-the-command-line) introduced by [@anonrig](https://x.com/yagiznizipli).

We also had good posts about this topic, like this one by Marvin Hagemeister [Speeding up the JavaScript ecosystem - npm scripts](https://marvinh.dev/blog/speeding-up-javascript-ecosystem-part-4/),
which showed some optimization opportunities I used to improve `npm run` overhead.

All of these discussions motivated me to investigate the overhead of `npm run` and see if I could reduce it, and here's what I found.

## [Baseline](#baseline)

First, let's create a simple script to measure the overhead of `npm run`:

```json
{
  "scripts": {
    "echo": "echo 1"
  }
}
```

When I started working on this, the npm version was `10.5.1`, if we try run this command with [hyperfine](https://github.com/sharkdp/hyperfine), we will get the following result:

```bash
$ hyperfine --warmup 3 "npm run echo"
Benchmark 1: npm run echo
  Time (mean ± σ):     117.1 ms ±   2.7 ms    [User: 108.5 ms, System: 31.5 ms]
  Range (min … max):   113.4 ms … 128.0 ms    25 runs
```

> If you use [asdf](https://asdf-vm.com) the overhead will be higher because of the `shim approach`, I recommend you to use [nvm](https://github.com/nvm-sh/nvm).

## [Measuring the overhead](#measuring-the-overhead)

To start measuring the overhead, I used the flag `--cpu-prof` and got the following graph representing the first `60ms` of executing the `npm run echo` command:

<a href="/images/posts/2024/06/npm-10-5-1-cpu-prof.png" target="_blank">
  <img
    style={{ width: '100%' }}
    src="/images/posts/2024/06/npm-10-5-1-cpu-prof.png"
    alt="The initial overhead of npm run using --cpu-prof"
  />
</a>

> The chart was generated using `vscode`, just open the `.cpuprofile` file, and click in the `show flame graph` icon on top-right.

The `Module._load` functions represent the `cjs loader` of Node.js, this means we are spending a lot of time loading `cjs` modules.

But just in this graph, we can't see what is being loaded, so since I am familiar with the Node.js codebase, why not emit some trace data in the `Module._load` function to see what is being loaded?

## [Improving the tooling](#improving-the-tooling)

My initial attempt to generate some tracing data for `Module._load` gave me the following result:

```plain
MODULE 1484165: TIMING [...shortened.../node_modules/make-fetch-happen/lib/cache/index.js] [./entry.js]: 44.579735 ms
MODULE 1484165: TIMING [...shortened.../node_modules/make-fetch-happen/lib/fetch.js] [./cache/index.js]: 45.353002000000004 ms
MODULE 1484165: TIMING [...shortened.../node_modules/make-fetch-happen/lib/index.js] [./fetch.js]: 48.313565999999994 ms
MODULE 1484165: TIMING [...shortened.../node_modules/npm-registry-fetch/lib/index.js] [make-fetch-happen]: 49.179769 ms
MODULE 1484165: TIMING [...shortened.../lib/utils/replace-info.js] [npm-registry-fetch]: 66.43049099999999 ms
MODULE 1484165: TIMING [...shortened.../lib/utils/error-message.js] [./replace-info.js]: 66.59006400000001 ms
MODULE 1484165: TIMING [...shortened.../lib/utils/exit-handler.js] [./error-message.js]: 77.62554 ms
MODULE 1484165: TIMING [...shortened.../lib/cli-entry.js] [./utils/exit-handler.js]: 89.835263 ms
MODULE 1484165: TIMING [] [...shortened.../bin/npm-cli.js]: 122.78886299999999 ms
```

This was so helpful that I opened a PR on Node.js to land this as a feature:

<a
  href="https://github.com/nodejs/node/pull/52213"
  target="_blank"
  rel="noopener"
>
  <img
    style={{ maxWidth: '100%' }}
    src="/images/posts/2024/06/print-load-time-pr.jpeg"
    alt="PR to print amount of load time of a module"
  />
</a>

With help of [Joyee Cheung](https://github.com/joyeecheung), we improved this feature to emit `trace_events`, that produces a `JSON` file that can be visualized in `chrome://tracing`.

This PR was landed on [v22.3.0](https://github.com/nodejs/node/pull/53379), and you can use it with the following command:

```bash
$ node --trace-event-categories node.module_timer --trace-event-file-pattern 'trace-events.log' your-script.js
```

Then import the `trace-events.log` file into `chrome://tracing` and you will get a graph like this:

<a href="/images/posts/2024/06/npm-run-tracing.png" target="_blank">
  <img
    style={{ width: '100%' }}
    src="/images/posts/2024/06/npm-run-tracing.png"
    alt="Using the new feature to trace the load time of a module"
  />
</a>

Now we have everything we need to start optimizing the `npm run`.

## [Lazy-loading dependencies](#lazy-loading-dependencies)

All the dependencies of `npm` are loaded for a reason, and we can't just remove them, but we can try to load them lazily.

To lazy load a dependency on `commonjs` is very simple, let's use the following image as example:

<a href="/images/posts/2024/06/example-of-lazy-loading.png" target="_blank">
  <img
    style={{ width: '100%' }}
    src="/images/posts/2024/06/example-of-lazy-loading.png"
    alt="In the image, we moved the require function of the dependency we want to lazy-load from the top of the script to be called only when needed."
  />
</a>

In the image, we moved the `require` of the dependency we want to lazy-load from the top of the script to be called only when needed.

Using this pattern, I started looking for all dependencies, one by one, that could be lazy-loaded, and I got the following PRs:

- `npm/cli` [perf: avoid importing npm-registry-fetch for replace-info](https://github.com/npm/cli/pull/7314)
  - This one was superseded by [this PR](https://github.com/npm/cli/pull/7334).
- `npm/package-json` [fix(perf): lazy load un-common dependencies for npm run](https://github.com/npm/package-json/pull/87)
- `npm/cli` [fix(perf): avoid importing the entire semver package for update-notifier](https://github.com/npm/cli/pull/7346)
- `npm/cli` [fix: lazy load validate npm package name on error message](https://github.com/npm/cli/pull/7347)
- `npm/package-json` [perf: only import necessary functions from semver](https://github.com/npm/package-json/pull/88)
- `builtins` [perf: only import used function from semver](https://github.com/juliangruber/builtins/pull/53)
- `npm/cli` [fix(perf): lazy load workspace dependency](https://github.com/npm/cli/pull/7352)
- `npm/cli` [fix(perf): only import what is needed for type-defs](https://github.com/npm/cli/pull/7359)
- `npm/cli` [fix(perf): only initialize workpaces when we are inside a workspace](https://github.com/npm/cli/pull/7360)
- `npm/package-json` [fix(perf): lazy load glob on normalize.js ](https://github.com/npm/package-json/pull/89)
- `npm/package-json` [fix(perf): lazy load hosted git info on normalize](https://github.com/npm/package-json/pull/90)

## [Results](#results)

All these PRs was released on `npm@10.5.2`, and if we run the same benchmark again, we will get the following result:

```bash
$ npm i -g npm@10.5.2
$ hyperfine --warmup 3 "npm run echo"
Benchmark 1: npm run echo
  Time (mean ± σ):      87.9 ms ±   1.3 ms    [User: 77.0 ms, System: 23.9 ms]
  Range (min … max):    86.3 ms …  92.3 ms    33 runs
```

Also, after a huge refactor on terminal display functionalities by [Luke Karrys](https://x.com/lukekarrys) on [this PR](https://github.com/npm/cli/pull/7339), on `npm@10.6.0` we got another improvement:

```bash
$ npm i -g npm@10.6.0
$ hyperfine --warmup 3 "npm run echo"
Benchmark 1: npm run echo
  Time (mean ± σ):      79.6 ms ±   0.8 ms    [User: 71.3 ms, System: 19.5 ms]
  Range (min … max):    78.2 ms …  81.8 ms    37 runs
```

In total, we went from `117ms` to `80ms`, which represents a 46% improvement in `npm run` overhead.

## [What about the alternatives?](#what-about-the-alternatives)

In case you are wondering, what if we compare it to other tools like `bun run` and `node --run` or `pnpm`, well, here is the result:

```bash
$ hyperfine --warmup 3 "npm run echo" "node --run echo" "pnpm run echo" "bun run echo"
Benchmark 1: npm run echo
  Time (mean ± σ):      81.8 ms ±   1.1 ms    [User: 70.6 ms, System: 20.1 ms]
  Range (min … max):    80.3 ms …  84.8 ms    36 runs

Benchmark 2: node --run echo
  Time (mean ± σ):       4.2 ms ±   0.4 ms    [User: 2.0 ms, System: 2.3 ms]
  Range (min … max):     3.5 ms …   5.6 ms    568 runs

  Warning: Command took less than 5 ms to complete. Results might be inaccurate.

Benchmark 3: pnpm run echo
  Time (mean ± σ):     285.2 ms ±   3.2 ms    [User: 254.3 ms, System: 48.4 ms]
  Range (min … max):   281.4 ms … 290.5 ms    10 runs

Benchmark 4: bun run echo
  Time (mean ± σ):       5.4 ms ±   0.4 ms    [User: 2.0 ms, System: 3.5 ms]
  Range (min … max):     4.7 ms …   6.9 ms    424 runs

  Warning: Command took less than 5 ms to complete. Results might be inaccurate.

Summary
  'node --run echo' ran
    1.31 ± 0.15 times faster than 'bun run echo'
   19.67 ± 1.71 times faster than 'npm run echo'
   68.56 ± 5.93 times faster than 'pnpm run echo'
```

> For this latest command, I used npm v10.8.1, bun v1.1.17, node v22.3.0 and pnpm v9.4.0

## [Conclusion](#conclusion)

I want to thank the NPM team, especially [Luke Karrys](https://x.com/lukekarrys)
and [@wraithgar](https://github.com/wraithgar) for helping me get all these PRs.

Optimizing NPM is not an easy task as the world (and many versions of Node.js) depend on it,
and even small mistakes or premature optimizations can break the world, so I have huge respect for the NPM team for doing this work.

Also, not all improvements should be merged, and that's okay.
We need to be careful with the trade-offs we are making, my optimizations were focused on making as few changes as possible
while keeping the codebase maintainable and readable. Sometimes saving 5ms isn't worth the added complexity to the codebase, I had a good example of that in [this PR](https://github.com/jslicense/spdx-correct.js/pull/43).

There is a huge ocean of improvements that can be made to the JS ecosystem that are waiting to be explored,
and I hope this post can inspire and also give some tips on how to start exploring this ocean.
